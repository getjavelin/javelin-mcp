1. Prompt Injection: Manipulating LLM behavior through malicious inputs

2. Tool Poisoning: Hiding malicious instructions in tool descriptions

3. Excessive Permissions: Exploiting overly permissive tool access
  - [GitHub MCP Exploited: Accessing private repositories via MCP](https://invariantlabs.ai/blog/mcp-github-vulnerability)

4. Rug Pull Attacks: Exploiting tool definition mutations

5. Tool Shadowing: Overriding legitimate tools with malicious ones

6. Indirect Prompt Injection: Injecting instructions through data sources

7. Token Theft: Exploiting insecure token storage

8. Malicious Code Execution: Executing arbitrary code through vulnerable tools
  - [Remote Prompt Injection in GitLab Duo Leads to Source Code Theft](https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo)

9. Remote Access Control: Gaining unauthorized system access

10. Multi-Vector Attacks: Combining multiple vulnerabilities

--

- https://simonwillison.net/tags/prompt-injection/  
- https://thehackernews.com/2025/07/critical-vulnerability-in-anthropics.html

